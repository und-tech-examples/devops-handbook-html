<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

    <title>DOHB-ch_10</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>

  


<link href="../../calibreHtmlOutBasicCss.css" type="text/css" rel="stylesheet" />

</head>
<body>

<div class="calibreMeta">
  <div class="calibreMetaTitle">
  
  
    
    <h1>
      <a href="../../../p4zbp-8mxvm.html">The DevOps Handbook How to Create World-Class Agility, Reliability & Security in Technology Organizations
</a>
    </h1>
    
    
  
  </div>
  <div class="calibreMetaAuthor">
    Gene Kim, Patrick Debois, John Willis, Jez Humble, John Allspaw

  </div>
</div>

<div class="calibreMain">

  <div class="calibreEbookContent">
    
      <div class="calibreEbNavTop">
        
          <a href="DOHB-ch_09.html" class="calibreAPrev">previous page</a>
        

        
          <a href="DOHB-ch_11.html" class="calibreANext"> next page</a>
        
      </div>
    

    
<a id="ep-file-23" class="calibre1"></a><a data-ep_ppid="Page-__-157" id="Page-__-157" class="calibre1"></a><a data-ep_ppid="Page-__-158" id="Page-__-158" class="calibre1"></a><div id="_idContainer055" class="calibre10"><span epub:type="pagebreak" id="pg122" title="122"></span> <h1 class="chapter-title-b" data-ep_lpid="ch10" id="_idParaDest-22" title="10 Enable Fast and Reliable Automated Testing"><span class="chapter-number1">10</span><span epub:type="pagebreak" id="pg123" title="123"></span>Enable Fast and Reliable Automated Testing </h1>
 <p class="body">At this point, Development and QA are using production-like environments in their daily work, and we are successfully integrating and running our code into a production-like environment for every feature that is accepted, with all changes checked in to version control. However, we are likely to get undesired outcomes if we find and fix errors in a separate test phase, executed by a separate QA department only after all development has been completed. And, if testing is only performed a few times a year, developers learn about their mistakes months after they introduced the change that caused the error. By then, the link between cause and effect has likely faded, solving the problem requires firefighting and archaeology, and, worst of all, our ability to learn from the mistake and integrate it into our future work is significantly diminished. </p>
 <p class="body">Automated testing addresses another significant and unsettling problem. <span id="ch10-1"></span>Gary Gruver observes that “without automated testing, the more code we write, the more time and money is required to test our code—in most cases, this is a totally unscalable business model for any technology organization.” </p>
 <p class="body">Although Google now undoubtedly exemplifies a culture that values automated testing at scale, this wasn’t always the case. In 2005, when Mike Bland joined the organization, deploying to Google.com was often extremely problematic, especially for the Google Web Server (GWS) team. </p>
 <p class="body">As Bland explains, “The GWS team had gotten into a position in the mid 2000s where it was extremely difficult to make changes to the web server, a C++ application that handled all requests to Google’s home page and many other Google web pages. As important and prominent as Google.com was, being on the GWS team was not a glamorous assignment—it was often the dumping ground for all the different teams who were creating various search functionality, all of whom were developing code independently of each other. <span id="ch10-2"></span>They had problems such as builds and tests taking too long, code being put into <span epub:type="pagebreak" id="pg124" title="124"></span>production without being tested, and teams checking in large, infrequent changes that conflicted with those from other teams.” </p>
 <p class="body" data-ep_ppid="Page-__-159" id="Page-__-159">The consequences of this were large—search results could have errors or become unacceptably slow, affecting thousands of search queries on Google.com. The potential result was not only loss of revenue, but customer trust. </p>
 <p class="body" id="ch10-3">Bland describes how it affected developers deploying changes, “Fear became the mind-killer. Fear stopped new team members from changing things because they didn’t understand the system. But fear also stopped experienced people from changing things because they understood it all too well.”<sup class="footnotes"><span id="footnote-063-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-063">†</a></span></sup> Bland was part of the group that was determined to solve this problem. </p>
 <p class="body">GWS team lead Bharat Mediratta believed automated testing would help. <span id="ch10-5"></span>As Bland describes, “They created a hard line: no changes would be accepted into GWS without accompanying automated tests. They set up a continuous build and religiously kept it passing. They set up test coverage monitoring and ensured that their level of test coverage went up over time. They wrote up policy and testing guides, and insisted that contributors both inside and outside the team follow them.” </p>
 <p class="body">The results were startling. <span id="ch10-6"></span>As Bland notes, “GWS quickly became one of the most productive teams in the company, integrating large numbers of changes from different teams every week while maintaining a rapid release schedule. New team members were able to make productive contributions to this complex system quickly, thanks to good test coverage and code health. Ultimately, their radical policy enabled the Google.com home page to quickly expand its capabilities and thrive in an amazingly fast-moving and competitive technology landscape.” </p>
 <p class="body">But GWS was still a relatively small team in a large and growing company. The team wanted to expand these practices across the entire organization. Thus, the Testing Grouplet was born, an informal group of engineers who wanted <span epub:type="pagebreak" id="pg125" title="125"></span>to elevate automated testing practices across the entire organization. <span id="ch10-7"></span>Over the next five years, they helped replicate this culture of automated testing across all of Google.<sup class="footnotes"><span id="footnote-062-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-062">‡</a></span></sup> </p>
 <p class="body">Now when any Google developer commits code, it is automatically run against a suite of hundreds of thousands of automated tests. If the code passes, it is automatically merged into trunk, ready to be deployed into production. Many Google properties build hourly or daily, then pick which builds to release; others adopt a continuous “Push on Green” delivery philosophy. </p>
 <p class="body">The stakes are higher than ever—a single code deployment error at Google can take down every property, all at the same time (such as a global infrastructure change or when a defect is introduced into a core library that every property depends upon). </p>
 <a data-ep_ppid="Page-__-160" id="Page-__-160" class="calibre1"></a><p class="body" id="ch10-8">Eran Messeri, an engineer in the Google Developer Infrastructure group, notes, “Large failures happen occasionally. You’ll get a ton of instant messages and engineers knocking on your door. [When the deployment pipeline is broken,] we need to fix it right away, because developers can no longer commit code. Consequently, we want to make it very easy to roll back.” </p>
 <p class="body">What enables this system to work at Google is engineering professionalism and a high-trust culture that assumes everyone wants to do a good job, as well as the ability to detect and correct issues quickly. <span id="ch10-9"></span>Messeri explains, “There are no hard policies at Google, such as, ‘If you break production for more than ten projects, you have an SLA to fix the issue within ten minutes.’ Instead, there is mutual respect between teams and an implicit agreement that everyone does whatever it takes to keep the deployment pipeline running. We all know that one day, I’ll break your project by accident; the next day, you may break mine.” </p>
 <p class="body">What Mike Bland and the Testing Grouplet team achieved has made Google one of the most productive technology organizations in the world. By 2013, automated testing and continuous integration at Google enabled over four thousand small teams to work together and stay productive, all simultaneously developing, integrating, testing, and deploying their code into production. <span id="ch10-10"></span>All their code is in a single, shared repository, made up of billions of files, all <span epub:type="pagebreak" id="pg126" title="126"></span>being continuously built and integrated, with 50% of their code being changed each month. <span id="ch10-11"></span>Some other impressive statistics on their performance include: </p>
 <ul class="calibre12"> <li class="bullets"><span class="black">40,000 code commits/day</span> </li>
 <li class="bullets"><span class="black">50,000 builds/day (on weekdays, this may exceed 90,000)</span> </li>
 <li class="bullets"><span class="black">120,000 automated test suites</span> </li>
 <li class="bullets"><span class="black">75 million test cases run daily</span> </li>
 <li class="bullets"><span class="black">100+ engineers working on the test engineering, continuous integration, and release engineering tooling to increase developer productivity (making up 0.5% of the R&amp;D workforce)</span> </li>
 </ul>
 <p class="body">In the remainder of this chapter, we will go through the continuous integration practices required to replicate these outcomes. </p>
 <h2 data-ep_ppid="Page-__-161" id="Page-__-161" class="calibre7">CONTINUOUSLY BUILD, TEST, AND INTEGRATE OUR CODE AND ENVIRONMENTS </h2>
 <p class="body">Our goal is to build quality into our product, even at the earliest stages, by having developers build automated tests as part of their daily work. This creates a fast feedback loop that helps developers find problems early and fix them quickly, when there are the fewest constraints (e.g., time, resources). </p>
 <p class="body">In this step, we create automated test suites that increase the frequency of integration and testing of our code and our environments from periodic to continuous. We do this by building our deployment pipeline, which will perform integration of our code and environments and trigger a series of tests every time a new change is put into version control.<sup class="footnotes"><span id="footnote-061-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-061">§</a></span></sup> (See <a href="../Text/DOHB-ch_10.html#figure-13" class="calibre1">figure 13</a>.) </p>
 <p class="body" id="ch10-13">The deployment pipeline, first defined by Jez Humble and David Farley in their book <i class="calibre5">Continuous Delivery: Reliable Software Releases Through Build, Test, <span epub:type="pagebreak" id="pg127" title="127"></span>and Deployment Automation</i>, ensures that all code checked in to version control is automatically built and tested in a production-like environment. By doing this, we find any build, test, or integration errors as soon as a change is introduced, enabling us to fix them immediately. Done correctly, this allows us to always be assured that we are in a deployable and shippable state. </p>
 <p class="body">To achieve this, we must create automated build and test processes that run in dedicated environments. This is critical for the following reasons: </p>
 <ul data-ep_ppid="Page-__-162" id="Page-__-162" class="calibre12"> <li class="bullets"><span class="black">Our build and test process can run all the time, independent of the work habits of individual engineers.</span> </li>
 <li class="bullets"><span class="black">A segregated build and test process ensures that we understand all the dependencies required to build, package, run, and test our code (i.e., removing the “it worked on the developer’s laptop, but it broke in production” problem). </span></li>
 <li class="bullets"><span class="black">We can package our application to enable the repeatable installation of code and configurations into an environment (e.g., on Linux RPM, yum, npm; on Windows, OneGet; alternatively framework-specific packaging systems can be used, such as EAR and WAR files for Java, gems for Ruby, etc.). </span></li>
 <li class="bullets"><span class="black">Instead of putting our code in packages, we may choose to package our applications into deployable containers (e.g., Docker, Rkt, LXD, AMIs).</span> </li>
 <li class="bullets"><span class="black">Environments can be made more production-like in a way that is consistent and repeatable (e.g., compilers are removed from the environment, debugging flags are turned off, etc.). </span></li>
 </ul>
 <p class="body">Our deployment pipeline validates after every change that our code successfully integrates into a production-like environment. It becomes the platform through which testers request and certify builds during acceptance testing and usability testing, and it will run automated performance and security validations. </p>
 <p class="captions" id="figure-13">&gt;<img alt="" src="../Images/ch_10.png" class="ep_cover_page"/>  <b class="captions1">Figure 13:</b> The deployment pipeline (Source: Humble and Farley, <i class="captions2">Continuous Delivery</i>, 3.) </p>
 <p class="body"><span epub:type="pagebreak" id="pg128" title="128"></span>Furthermore, it will be used to self-service builds to UAT (user acceptance testing), integration testing, and security testing environments. In future steps, as we evolve the deployment pipeline, it will also be used to manage all activities required to take our changes from version control to deployment. </p>
 <p class="body">A variety of tools have been designed to provide deployment pipeline functionality, many of them open source (e.g., Jenkins, ThoughtWorks Go, Concourse, Bamboo, Microsoft Team Foundation Server, TeamCity, Gitlab CI, as well as cloud-based solutions such as Travis CI and Snap).<sup class="footnotes"><span id="footnote-060-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-060">¶</a></span></sup> </p>
 <p class="body" data-ep_ppid="Page-__-163" id="Page-__-163">We begin the deployment pipeline by running the commit stage, which builds and packages the software, runs automated unity tests, and performs additional validation such as static code analysis, duplication and test coverage analysis, and checking style.<sup class="footnotes"><span id="footnote-059-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-059">**</a></span></sup> If successful, this triggers the acceptance stage, which automatically deploys the packages created in the commit stage into a production-like environment and runs the automated acceptance tests. </p>
 <p class="body">Once changes are accepted into version control, we want to package our code only once, so that the same packages are used to deploy code throughout our entire deployment pipeline. By doing this, code will be deployed into our integrated test and staging environments in the same way that it is deployed into production. This reduces variances that can avoid downstream errors that are difficult to diagnose (e.g., using different compilers, compiler flags, library versions, or configurations).<sup class="footnotes"><span id="footnote-058-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-058">††</a></span></sup> </p>
 <p class="body">The goal of the deployment pipeline is to provide everyone in the value stream, especially developers, the fastest possible feedback that a change has taken <span epub:type="pagebreak" id="pg129" title="129"></span>us out of a deployable state. This could be a change to our code, to any of our environments, to our automated tests, or even to the deployment pipeline infrastructure (e.g., a Jenkins configuration setting). </p>
 <p class="body">As a result, our deployment pipeline infrastructure becomes as foundational for our development processes as our version control infrastructure. Our deployment pipeline also stores the history of each code build, including information about which tests were performed on which build, which builds have been deployed to which environment, and what the test results were. In combination with the information in our version control history, we can quickly determine what caused our deployment pipeline to break and, likely, how to fix the error. </p>
 <p class="body">This information also helps us fulfill evidence requirements for audit and compliance purposes, with evidence being automatically generated as part of daily work. </p>
 <p class="body">Now that we have a working deployment pipeline infrastructure, we must create our <i class="calibre5">continuous integration</i> practices, which require three capabilities: </p>
 <ul class="calibre12"> <li class="bullets"><span class="black">A comprehensive and reliable set of automated tests that validate we are in a deployable state.</span> </li>
 <li class="bullets"><span class="black">A culture that “stops the entire production line” when our validation tests fail.</span> </li>
 <li class="bullets"><span class="black">Developers working in small batches on trunk rather than long-lived feature branches.</span> </li>
 </ul>
 <p class="body" data-ep_ppid="Page-__-164" id="Page-__-164">In the next section, we describe why fast and reliable automated testing is needed and how to build it. </p>
 <h2 id="sigil_toc_id_77" class="calibre7">BUILD A FAST AND RELIABLE AUTOMATED VALIDATION TEST SUITE </h2>
 <p class="body">In the previous step, we started to create the automated testing infrastructure that validates that we have a <i class="calibre5">green build</i> (i.e., whatever is in version control is in a buildable and deployable state). To underscore why we need to perform this integration and testing step continuously, consider what happens when we only perform this operation periodically, such as during a nightly build process. </p>
 <p class="body"><span epub:type="pagebreak" id="pg130" title="130"></span>Suppose we have a team of ten developers, with everyone checking their code into version control daily, and a developer introduces a change that breaks our nightly build and test job. In this scenario, when we discover the next day that we no longer have a green build, it will take minutes, or more likely hours, for our development team to figure out which change caused the problem, who introduced it, and how to fix it. </p>
 <p class="body">Worse, suppose the problem wasn’t caused by a code change, but was due to a test environment issue (e.g., an incorrect configuration setting somewhere). The development team may believe that they fixed the problem because all the unit tests pass, only to discover that the tests will still fail later that night. </p>
 <p class="body">Further complicating the issue, ten more changes will have been checked in to version control by the team that day. Each of these changes has the potential to introduce more errors that could break our automated tests, further increasing the difficulty of successfully diagnosing and fixing the problem. </p>
 <p class="body">In short, slow and periodic feedback kills. Especially for larger development teams. The problem becomes even more daunting when we have tens, hundreds, or even thousands of other developers checking their changes into version control each day. The result is that our builds and automated tests are frequently broken, and developers even stop checking their changes into version control (“Why bother, since the builds and tests are always broken?”). Instead they wait to integrate their code at the end of the project, resulting in all the undesired outcomes of large batch size, big bang integrations, and production deployments.<sup class="footnotes"><span id="footnote-057-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-057">‡‡</a></span></sup> </p>
 <p class="body" data-ep_ppid="Page-__-165" id="Page-__-165">To prevent this scenario, we need fast automated tests that run within our build and test environments whenever a new change is introduced into version control. In this way we can find and fix any problems immediately, as the Google Web Server example demonstrated. By doing this, we ensure our batches remains small, and, at any given point in time, we remain in a deployable state. </p>
 <p class="body">In general, automated tests fall into one of the following categories, from fastest to slowest: </p>
 <ul class="calibre12"> <li class="bullets"><span class="black"><b class="calibre6">Unit tests</b>: These typically test a single method, class, or function in isolation, providing assurance to the developer that their code <span epub:type="pagebreak" id="pg131" title="131"></span>operates as designed. For many reasons, including the need to keep our tests fast and stateless, unit tests often “stub out” databases and other external dependencies (e.g., functions are modified to return static, predefined values, instead of calling the real database).<sup class="footnotes"><span id="footnote-056-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-056">§§</a></span></sup></span> </li>
 <li class="bullets"><span class="black"><b class="calibre6">Acceptance tests</b>: These typically test the application as a whole to provide assurance that a higher level of functionality operates as designed (e.g., the business acceptance criteria for a user story, the correctness of an API), and that regression errors have not been introduced (i.e., we broke functionality that was previously operating correctly). <span id="ch10-14"></span>Humble and Farley define the difference between unit and acceptance testing as, “The aim of a unit test is to show that a single part of the application does what the programmer intends it to....The objective of acceptance tests is to prove that our application does what the customer meant it to, not that it works the way its programmers think it should.” After a build passes our unit tests, our deployment pipeline runs it against our acceptance tests. Any build that passes our acceptance tests is then typically made available for manual testing (e.g., exploratory testing, UI testing, etc.), as well as for integration testing.</span> </li>
 <li class="bullets"><span class="black"><b class="calibre6">Integration tests</b>: Integration tests are where we ensure that our application correctly interacts with other production applications and services, as opposed to calling stubbed out interfaces. <span id="ch10-15"></span>As Humble and Farley observe, “much of the work in the SIT environment involves deploying new versions of each of the applications until they all cooperate. In this situation the smoke test is usually a fully fledged set of acceptance tests that run against the whole application.” Integration tests are performed on builds that have passed our unit and acceptance tests. Because integration tests are often brittle, we want to minimize the number of integration tests and find as many of our defects as possible during unit and acceptance testing. The ability to use virtual or simulated versions of remote services when running acceptance tests becomes an essential architectural requirement.</span> </li>
 </ul>
 <p class="body" data-ep_ppid="Page-__-166" id="Page-__-166"><span epub:type="pagebreak" id="pg132" title="132"></span>When facing deadline pressures, developers may stop creating unit tests as part of their daily work, regardless of how we’ve defined ‘done.’ To detect this, we may choose to measure and make visible our test coverage (as a function of number of classes, lines of code, permutations, etc.), maybe even failing our validation test suite when it drops below a certain level (e.g., when less than 80% of our classes have unit tests).<sup class="footnotes"><span id="footnote-055-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-055">¶¶</a></span></sup> </p>
 <p class="body" id="ch10-16">Martin Fowler observes that, in general, “a ten-minute build [and test process] is perfectly within reason…[We first] do the compilation and run tests that are more localized unit tests with the database completely stubbed out. Such tests can run very fast, keeping within the ten minute guideline. However any bugs that involve larger scale interactions, particularly those involving the real database, won’t be found. The second stage build runs a different suite of tests [acceptance tests] that do hit the real database and involve more end-to-end behavior. This suite may take a couple of hours to run.” </p>
 <h3 id="sigil_toc_id_78" class="calibre11">CATCH ERRORS AS EARLY IN OUR AUTOMATED TESTING AS POSSIBLE </h3>
 <p class="body">A specific design goal of our automated test suite is to find errors as early in the testing as possible. This is why we run faster-running automated tests (e.g., unit tests) before slower-running automated tests (e.g., acceptance and integration tests), which are both run before any manual testing. </p>
 <p class="body">Another corollary of this principle is that any errors should be found with the fastest category of testing possible. If most of our errors are found in our acceptance and integration tests, the feedback we provide to developers is orders of magnitude slower than with unit tests—and integration testing requires using scarce and complex integration test environments, which can only be used by one team at a time, further delaying feedback. </p>
 <p class="body">Furthermore, not only are errors detected during integration testing difficult and time-consuming for developers to reproduce, even validating that it has been fixed is difficult (i.e., a developer creates a fix but then needs to wait four hours to learn whether the integration tests now pass). </p>
 <p class="body">Therefore, whenever we find an error with an acceptance or integration test, we should create a unit test that could find the error faster, earlier, and cheaper. <span id="ch10-17"></span>Martin Fowler described the notion of the “ideal testing pyramid,” where we are able to catch most of our errors using our unit tests. (See <a href="../Text/DOHB-ch_10.html#figure-14" class="calibre1">figure 14</a>.) In <span epub:type="pagebreak" id="pg133" title="133"></span>contrast, in many testing programs the inverse is true, where most of the investment is in manual and integration testing. </p>
 <a data-ep_ppid="Page-__-167" id="Page-__-167" class="calibre1"></a><p class="captions" id="figure-14"><img alt="" src="../Images/ch_101.png" class="ep_cover_page"/> <b class="captions1">Figure 14:</b> The ideal and non-ideal automated testing pyramids (Source: Martin Fowler, “TestPyramid.”) </p>
 <p class="body">If we find that unit or acceptance tests are too difficult and expensive to write and maintain, it’s likely that we have an architecture that is too tightly-coupled, where strong separation between our module boundaries no longer exist (or maybe never existed). In this case, we will need to create a more loosely-coupled system so modules can be independently tested without integration environments. Acceptance test suites for even the most complex applications that run in minutes are possible. </p>
 <h3 id="sigil_toc_id_79" class="calibre11">ENSURE TESTS RUN QUICKLY (IN PARALLEL, IF NECESSARY) </h3>
 <p class="body">Because we want our tests to run quickly, we need to design our tests to run in parallel, potentially across many different servers. We may also want to run different categories of tests in parallel. For example, when a build passes our acceptance tests, we may run our performance testing in parallel with our security testing, as shown in figure 15. We may or may not allow manual exploratory testing until the build has passed all our automated tests—which enables faster feedback, but may also allow manual testing on builds that will eventually fail. </p>
 <p class="body" data-ep_ppid="Page-__-168" id="Page-__-168">We make any build that passes all our automated tests available to use for exploratory testing, as well as for other forms of manual or resource-intensive <span epub:type="pagebreak" id="pg134" title="134"></span>testing (such as performance testing). We want to do all such testing as frequently as possible and practical, either continually or on a schedule. </p>
 <p class="captions"><img alt="" src="../Images/ch_102.png" class="ep_cover_page"/> <b class="captions1">Figure 15:</b> Running automated and manual tests in parallel <br class="calibre8"/>(Source: Humble and Farley, <i class="captions2">Continuous Delivery</i>, Kindle edition, location 3868.) </p>
 <p class="body">Any tester (which includes all our developers) should use the latest build that has passed all the automated tests, as opposed to waiting for developers to flag a specific build as ready to test. By doing this, we ensure that testing happens as early in the process as possible. </p>
 <h3 id="sigil_toc_id_80" class="calibre11">WRITE OUR AUTOMATED TESTS BEFORE WE WRITE THE CODE (“TEST-DRIVEN DEVELOPMENT”) </h3>
 <p class="body">One of the most effective ways to ensure we have reliable automated testing, is to write those tests as part of our daily work, using techniques such as <i class="calibre5">test-driven development</i> (TDD) and <i class="calibre5">acceptance test-driven development</i> (ATDD). This is when we begin every change to the system by first writing an automated test that validates the expected behavior <i class="calibre5">fails</i>, and then we write the code to make the tests pass. </p>
 <p class="body" id="ch10-18">This technique was developed by Kent Beck in the late 1990s as part of Extreme Programming, and has the following three steps: </p>
 <ol data-ep_ppid="Page-__-169" id="Page-__-169" class="calibre15"> <li class="bullets"><span class="black">Ensure the tests fail. “Write a test for the next bit of functionality you want to add.” Check in.</span> </li>
 <li class="bullets"><span class="black"><span epub:type="pagebreak" id="pg135" title="135"></span>Ensure the tests pass. “Write the functional code until the test passes.”Check in.</span> </li>
 <li class="bullets"><span class="black">“Refactor both new and old code to make it well structured.”Ensure the tests pass. Check in again. </span></li>
 </ol>
 <p class="body">These automated test suites are checked in to version control alongside our code, which provides a living, up-to-date specification of the system. Developers wishing to understand how to use the system can look at this test suite to find working examples of how to use the system’s API.<sup class="footnotes"><span id="footnote-054-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-054">***</a></span></sup> </p>
 <h3 id="sigil_toc_id_81" class="calibre11">AUTOMATE AS MANY OF OUR MANUAL TESTS AS POSSIBLE </h3>
 <p class="body">Our goal is to find as many code errors through our automated test suites, reducing our reliance on manual testing. <span id="ch10-20"></span>In her 2013 presentation at Flowcon titled “On the Care and Feeding of Feedback Cycles,” Elisabeth Hendrickson observed, “Although testing can be automated, creating quality cannot. To have humans executing tests that should be automated is a waste of human potential.” </p>
 <p class="body">By doing this, we enable all our testers (which, of course, includes developers) work on high-value activities that cannot be automated, such as exploratory testing or improving the test process itself. </p>
 <p class="body" id="ch10-21">However, merely automating all our manual tests may create undesired outcomes—we do not want automated tests that are unreliable or generate false positives (i.e., tests that should have passed because the code is functionally correct but failed due to problems such as slow performance, causing timeouts, uncontrolled starting state, or unintended state due to using database stubs or shared test environments). </p>
 <p class="body">Unreliable tests that generate false positives create significant problems—they waste valuable time (e.g., forcing developers to re-run the test to determine whether there is actually a problem), increase the overall effort of running and interpreting our test results, and often result in stressed developers ignoring test results entirely or turning off the automated tests in favor of focusing on creating code. </p>
 <p class="body"><span epub:type="pagebreak" id="pg136" title="136"></span>The result is always the same: we detect the problems later, the problems are more difficult to fix, and our customers have worse outcomes, which in turn creates stress across the value stream. </p>
 <p class="body" data-ep_ppid="Page-__-170" id="Page-__-170">To mitigate of this, a small number of reliable, automated tests are almost always preferable over a large number of manual or unreliable automated tests. Therefore, we focus on automating only the tests that genuinely validate the business goals we are trying to achieve. If abandoning a test results in production defects, we should add it back to our manual test suite, with the ideal of eventually automating it. </p>
 <p class="body" id="ch10-22">As Gary Gruver, formerly VP of Quality Engineering, Release Engineering, and Operations for Macys.com, described observes, “For a large retailer e-commerce site, we went from running 1,300 manual tests that we ran every ten days to running only ten automated tests upon every code commit—it’s far better to run a few tests that we trust than to run tests that aren’t reliable. Over time, we grew this test suite to having hundreds of thousands of automated tests.” </p>
 <p class="body">In other words, we start with a small number of reliable automated tests and add to them over time, creating an ever-increasing level of assurance that we will quickly detect any changes to the system that take us out of a deployable state. </p>
 <h3 id="sigil_toc_id_82" class="calibre11">INTEGRATE PERFORMANCE TESTING INTO OUR TEST SUITE </h3>
 <p class="body">All too often, we discover that our application performs poorly during integration testing or after it has been deployed to production. Performance problems are often difficult to detect, such as when things slow down over time, going unnoticed until it is too late (e.g., database queries without an index). And many problems are difficult to solve, especially when they are caused by architectural decisions we made or unforeseen limitations of our networking, database, storage, or other systems. </p>
 <p class="body">Our goal is to write and run automated performance tests that validate our performance across the entire application stack (code, database, storage, network, virtualization, etc.) as part of the deployment pipeline, so we detect problems early, when the fixes are cheapest and fastest. </p>
 <p class="body">By understanding how our application and environments behave under a production-like load, we can do a far better job at capacity planning, as well as detecting conditions such as: </p>
 <ul class="calibre12"> <li class="bullets"><span class="black"><span epub:type="pagebreak" id="pg137" title="137"></span>When our database query times grow non-linearly (e.g., we forget to turn on database indexing, and page load goes from one hundred minutes to thirty seconds).</span> </li>
 <li class="bullets"><span class="black">When a code change causes the number of database calls, storage use, or network traffic to increase ten-fold.</span> </li>
 </ul>
 <p class="body" data-ep_ppid="Page-__-171" id="Page-__-171">When we have acceptance tests that are able to be run in parallel, we can use them as the basis of our performance tests. For instance, suppose we run an e-commerce site and have identified “search” and “checkout” as two high-value operations that must perform well under load. To test this, we may run thousands of parallel search acceptance tests simultaneously with thousands of parallel checkout tests. </p>
 <p class="body">Due to the large amount of compute and I/O that is required to run performance tests, creating a performance testing environment can easily be more complex than creating the production environment for the application itself. Because of this, we may build our performance testing environment at the start of any project and ensure that we dedicate whatever resources are required to build it early and correctly. </p>
 <p class="body">To find performance problems early, we should log performance results and evaluate each performance run against previous results. For instance, we might fail the performance tests if performance deviates more than 2% from the previous run. </p>
 <h3 id="sigil_toc_id_83" class="calibre11">INTEGRATE NON-FUNCTIONAL REQUIREMENTS TESTING INTO OUR TEST SUITE </h3>
 <p class="body">In addition to testing that our code functions as designed and it performs under production-like loads, we also want to validate every other attribute of the system we care about. These are often called non-functional requirements, which include availability, scalability, capacity, security, and so forth. </p>
 <p class="body">Many of these requirements are fulfilled by the correct configuration of our environments, so we must also build automated tests to validate that our environments have been built and configured properly. For example, we want to enforce the consistency and correctness of the following, which many non-functional requirements rely upon (e.g., security, performance, availability): </p>
 <ul class="calibre12"> <li class="bullets"><span class="black">Supporting applications, databases, libraries, etc.</span> </li>
 <li class="bullets"><span class="black"><span epub:type="pagebreak" id="pg138" title="138"></span>Language interpreters, compilers, etc.</span> </li>
 <li class="bullets"><span class="black">Operating systems (e.g., audit logging enabled, etc.)</span> </li>
 <li class="bullets"><span class="black">All dependencies</span> </li>
 </ul>
 <p class="body" data-ep_ppid="Page-__-172" id="Page-__-172">When we use infrastructure as code configuration management tools (e.g., Puppet, Chef, Ansible, Salt, Bosh), we can use the same testing frameworks that we use to test our code to also test that our environments are configured and operating correctly (e.g., encoding environment tests into cucumber or gherkin tests). </p>
 <p class="body">Furthermore, similar to how we run analysis tools on our application in our deployment pipeline (e.g., static code analysis, test coverage analysis), we should run tools that analyze the code that constructs our environments (e.g., Foodcritic for Chef, puppet-lint for Puppet). We should also run any security hardening checks as part of our automated tests to ensure that everything is configured securely and correctly (e.g., server-spec). </p>
 <p class="body">At any point in time, our automated tests can validate that we have a green build and that we are in a deployable state. Now, we must create an Andon cord so that when someone breaks the deployment pipeline, we take all necessary steps to get back into a green build state. </p>
 <h2 id="sigil_toc_id_84" class="calibre7">PULL OUR ANDON CORD WHEN THE DEPLOYMENT PIPELINE BREAKS </h2>
 <p class="body">When we have a green build in our deployment pipeline, we have a high degree of confidence that our code and environment will operate as designed when we deploy our changes into production. </p>
 <p class="body">In order to keep our deployment pipeline in a green state, we will create a virtual Andon Cord, similar to the physical one in the Toyota Production System. Whenever someone introduces a change that causes our build or automated tests to fail, no new work is allowed to enter the system until the problem is fixed. And if someone needs help to resolve the problem, they can bring in whatever help they need, as in the Google example at the beginning of this chapter. </p>
 <p class="body">When our deployment pipeline is broken, at a minimum, we notify the entire team of the failure, so anyone can either fix the problem or roll-back the <span epub:type="pagebreak" id="pg139" title="139"></span>commit. We may even configure the version control system to prevent further code commits until the first stage (i.e., builds and unit tests) of the deployment pipeline is back in a green state. If the problem was due to an automated test generating a false positive error, the offending test should either be rewritten or removed.<sup class="footnotes"><span id="footnote-053-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-053">†††</a></span></sup> Every member of the team should be empowered to roll back the commit to get back into a green state. </p>
 <a data-ep_ppid="Page-__-173" id="Page-__-173" class="calibre1"></a><p class="body" id="ch10-23">Randy Shoup, former engineering director for Google App Engine, wrote about the importance of bringing the deployment back into a green state. “We prioritize the team goals over individual goals—whenever we help someone move their work forward, we help the entire team. This applies whether we’re helping someone fix the build or an automated test, or even performing a code review for them. And of course, we know that they’ll do the same for us, when we need help. This system worked without a lot of formality or policy—everyone knew that our job was not just ‘write code,’ but it was to ‘run a service.’ This is why we prioritized all quality issues, especially those related to reliability and scaling, at the highest level, treating them as a Priority 0 ‘show-stopper’ problems. From a systems perspective, these practices keep us from slipping backwards.” </p>
 <p class="body">When later stages of the deployment pipeline fail, such as acceptance tests or performance tests, instead of stopping all new work, we will have developers and testers on-call who are responsible for fixing these problems immediately. They should also create new tests that run at an earlier stage in the deployment pipeline to catch any future regressions. For example, if we discover a defect in our acceptance tests, we should write a unit test to catch the problem. Similarly, if we discover a defect in exploratory testing, we should write a unit or acceptance test. </p>
 <p class="body">To increase the visibility of automated test failures, we should create highly visible indicators so that the entire team can see when our build or automated tests are failing. Many teams have created highly visible build lights that get mounted on a wall, indicating the current build status, or other fun ways of telling the team the build is broken, including lava lamps, playing a voice sample or song, klaxons, traffic lights, and so forth. </p>
 <p class="body">In many ways, this step is more challenging than creating our builds and test servers—those were purely technical activities, whereas this step requires changing human behavior and incentives. However, continuous integration <span epub:type="pagebreak" id="pg140" title="140"></span>and continuous delivery require these changes, as we explore in the next section. </p>
 <h3 id="sigil_toc_id_85" class="calibre11">WHY WE NEED TO PULL THE ANDON CORD </h3>
 <p class="body">The consequence of not pulling the Andon cord and immediately fixing any deployment pipeline issues results in the all too familiar problem where it becomes ever more difficult to bring our applications and environment back into a deployable state. Consider the following situation: </p>
 <ul data-ep_ppid="Page-__-174" id="Page-__-174" class="calibre12"> <li class="bullets"><span class="black">Someone checks in code that breaks the build or our automated tests, but no one fixes it.</span> </li>
 <li class="bullets"><span class="black">Someone else checks in another change onto the broken build, which also doesn’t pass our automated tests—but no one sees the failing test results which would have enabled us to see the new defect, let alone fix it.</span> </li>
 <li class="bullets"><span class="black">Our existing tests don’t run reliably, so we are very unlikely to build new tests. (Why bother? We can’t even get the current tests to run.)</span> </li>
 </ul>
 <p class="body">When this happens, our deployments to any environment become as unreliable as when we had no automated tests or were using a waterfall method, where the majority of our problems are being discovered in production. The inevitable outcome of this vicious cycle is that we end up where we started, with an unpredictable “stabilization phase” that takes weeks or months where our whole team is plunged into crisis, trying to get all our tests to pass, taking shortcuts because of deadline pressures, and adding to our technical debt.<sup class="footnotes"><span id="footnote-052-backlink" class="calibre9"><a class="_idfootnotelink" epub:type="noteref" href="../Text/DOHB-ch_10.html#footnote-052">‡‡‡</a></span></sup> </p>
 <h2 id="sigil_toc_id_86" class="calibre7">CONCLUSION </h2>
 <p class="body">In this chapter, we have created a comprehensive set of automated tests to confirm that we have a green build that is still in a passing and deployable state. We have organized our test suites and testing activities into a deployment pipeline. We have also created the cultural norm of doing whatever it takes <span epub:type="pagebreak" id="pg141" title="141"></span>to get back into a green build state if someone introduces a change that breaks any of our automated tests. </p>
 <p class="body">By doing this, we set the stage for implementing continuous integration, which allows many small teams to independently and safely develop, test, and deploy code into production, delivering value to customers. </p>
 <hr class="calibre13"/>
 <div class="_idfootnotes"> <aside class="_idfootnote" epub:type="footnote" id="footnote-063"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-063-backlink">†</a></span><span id="ch10-4"> </span>Bland described that at Google, one of the consequences of having so many talented developers was that it created “imposter syndrome,” a term coined by psychologists to informally describe people who are unable to internalize their accomplishments. Wikipedia states that “despite external evidence of their competence, those exhibiting the syndrome remain convinced that they are frauds and do not deserve the success they have achieved. Proof of success is dismissed as luck, timing, or as a result of deceiving others into thinking they are more intelligent and competent than they believe themselves to be.” </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-062"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-062-backlink">‡</a></span><span> </span>They created training programs, pushed the famous <i class="calibre5">Testing on the Toilet</i> newsletter (which they posted in the bathrooms), the Test Certified roadmap and certification program, and led multiple “fix-it” days (i.e., improvement blitzes), which helped teams improve their automated testing processes so they could replicate the amazing outcomes that the GWS team was able to achieve. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-061"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-061-backlink">§</a></span><span id="ch10-12"> </span>In Development, <i class="calibre5">continuous integration</i> often refers to the continuous integration of multiple code branches into trunk and ensuring that it passes unit tests. However, in the context of continuous delivery and DevOps, continuous integration also mandates running on production-like environments and passing acceptance and integration tests. Jez Humble and David Farley disambiguate these by calling the latter CI+. In this book, <i class="calibre5">continuous integration</i> will always refer to CI+ practices. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-060"> <p class="footnotes2"><span><a data-ep_ppid="Page-__-175" id="Page-__-175" class="calibre1"></a>¶</span><span> </span>If we create containers in our deployment pipeline and have an architecture such as microservices, we can enable each developer to build immutable artifacts where developers assemble and run all the service components in an environment identical to production on their workstation. This enables developers to build and run more tests on their workstation instead of on testing servers, giving us even faster feedback on their work. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-059"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-059-backlink">**</a></span><span> </span>We may even require that these tools are run before changes are accepted into version control (e.g., get pre-commit hooks). We may also run these tools within the developer <i class="calibre5">integrated development environment</i> (IDE; where the developer edits, compiles, and runs code), which creates an even faster feedback loop. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-058"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-058-backlink">††</a></span><span> </span>We can also use containers, such as Docker, as the packaging mechanism. Containers enable the capability to write once, run anywhere. These containers are created as part of our build process and can be quickly deployed and run in any environment. Because the same container is run in every environment, we help enforce the consistency of all our build artifacts. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-057"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-057-backlink">‡‡</a></span><span> </span>It is exactly this problem that led to the development of continuous integration practices. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-056"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-056-backlink">§§</a></span><span> </span>There is a broad category of architectural and testing techniques used to handle the problems of tests requiring input from external integration points, including “stubs,” “mocks,” “service virtualization,” and so forth. This becomes even more important for acceptance and integration testing, which place far more reliance on external states. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-055"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-055-backlink">¶¶</a></span><span> </span>We should do this only when our teams already value automated testing—this type of metric is easily gamed by developers and managers. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-054"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-054-backlink">***</a></span><span id="ch10-19"> </span>Nachi Nagappan, E. Michael Maximilien, and Laurie Williams (from Microsoft Research, IBM Almaden Labs, and North Carolina State University, respectively) conducted a study that showed teams using TDD produced code 60%–90% better in terms of defect density than non-TDD teams, while taking only 15%–35% longer. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-053"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-053-backlink">†††</a></span><span> </span>If the process for rolling back the code is not well-known, a potential countermeasure is to schedule a <i class="calibre5">pair programmed rollback</i>, so that it can be better documented. </p>
 </aside>
 <aside class="_idfootnote" epub:type="footnote" id="footnote-052"> <p class="footnotes2"><span><a class="calibre1" href="../Text/DOHB-ch_10.html#footnote-052-backlink">‡‡‡</a></span><span id="ch10-24"> </span>This is sometimes called the <i class="calibre5">water-Scrum-fall anti-pattern</i>, which refers to when an organization claims to be using Agile-like practices, but, in reality, all testing and defect fixing are performed at the end of the project. </p>
 </aside>
 </div>
 </div>
<div class="calibre10"> <div id="_idContainer056" class="calibre10"> </div>
 </div>
<img id="floatBarImgId" src="chrome-extension://dbkmjjclgbiooljcegcddagnddjedmed/pics/save2-32.png" class="calibre3"/>



  </div>

  
  <div class="calibreToc">
    <h2><a href="../../../p4zbp-8mxvm.html"> Table of contents</a></h2>
     <div>
  <ul>
    <li>
      <a href="DOHB-0-FM-preface.html">Preface</a>
      <ul>
        <li>
          <a href="DOHB-0-FM-preface.html#sigil_toc_id_1">Aha!</a>
          <ul>
            <li>
              <a href="DOHB-0-FM-preface.html#sigil_toc_id_2">Gene Kim</a>
            </li>
            <li>
              <a href="DOHB-0-FM-preface.html#sigil_toc_id_3">Jez Humble</a>
            </li>
            <li>
              <a href="DOHB-0-FM-preface.html#Page-__-13">Patrick Debois</a>
            </li>
            <li>
              <a href="DOHB-0-FM-preface.html#sigil_toc_id_4">John Willis</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-0-FM-preface.html#sigil_toc_id_5">SPREADING THE AHA! MOMENT</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-0-FM-foreword.html">Foreword</a>
    </li>
    <li>
      <a href="DOHB-0-FM-introduction.html">Imagine a World Where Dev and Ops Become DevOps</a>
      <ul>
        <li>
          <a href="DOHB-0-FM-introduction.html#sigil_toc_id_6">An Introduction to The DevOps Handbook</a>
        </li>
        <li>
          <a href="DOHB-0-FM-introduction.html#sigil_toc_id_7">THE PROBLEM: SOMETHING IN YOUR ORGANIZATION MUST NEED IMPROVEMENT (OR YOU WOULDN’T BE READING THIS BOOK)</a>
          <ul>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_8">THE CORE, CHRONIC CONFLICT</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_9">DOWNWARD SPIRAL IN THREE ACTS</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#Page-__-25">WHY DOES THIS DOWNWARD SPIRAL HAPPEN EVERYWHERE?</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_10">THE COSTS: HUMAN AND ECONOMIC</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-0-FM-introduction.html#sigil_toc_id_11">THE ETHICS OF DEVOPS: THERE IS A BETTER WAY</a>
          <ul>
            <li>
              <a href="DOHB-0-FM-introduction.html#Page-__-27">BREAKING THE DOWNWARD SPIRAL WITH DEVOPS</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_12">THE BUSINESS VALUE OF DEVOPS</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_13">DEVOPS HELPS SCALE DEVELOPER PRODUCTIVITY</a>
            </li>
            <li>
              <a href="DOHB-0-FM-introduction.html#sigil_toc_id_14">THE UNIVERSALITY OF THE SOLUTION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-0-FM-introduction.html#sigil_toc_id_15">THE DEVOPS HANDBOOK: AN ESSENTIAL GUIDE</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-pt_01_text.html">Part I The Three Ways</a>
      <ul>
        <li>
          <a href="DOHB-pt_01_text.html#sigil_toc_id_16">A BRIEF HISTORY</a>
          <ul>
            <li>
              <a href="DOHB-pt_01_text.html#sigil_toc_id_17">THE LEAN MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-pt_01_text.html#sigil_toc_id_18">THE AGILE MANIFESTO</a>
            </li>
            <li>
              <a href="DOHB-pt_01_text.html#sigil_toc_id_19">AGILE INFRASTRUCTURE AND VELOCITY MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-pt_01_text.html#sigil_toc_id_20">THE CONTINUOUS DELIVERY MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-pt_01_text.html#sigil_toc_id_21">TOYOTA KATA</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_01.html">1 Agile, Continuous Delivery, and the Three Ways</a>
          <ul>
            <li>
              <a href="DOHB-ch_01.html#sigil_toc_id_22">THE MANUFACTURING VALUE STREAM</a>
            </li>
            <li>
              <a href="DOHB-ch_01.html#Page-__-43">THE TECHNOLOGY VALUE STREAM</a>
              <ul>
                <li>
                  <a href="DOHB-ch_01.html#sigil_toc_id_23">FOCUS ON DEPLOYMENT LEAD TIME</a>
                  <ul>
                    <li>
                      <a href="DOHB-ch_01.html#sigil_toc_id_24">Defining Lead Time vs. Processing Time</a>
                    </li>
                    <li>
                      <a href="DOHB-ch_01.html#Page-__-45">The Common Scenario: Deployment Lead Times Requiring Months</a>
                    </li>
                    <li>
                      <a href="DOHB-ch_01.html#sigil_toc_id_25">Our DevOps Ideal: Deployment Lead Times of Minutes</a>
                    </li>
                  </ul>
                </li>
                <li>
                  <a href="DOHB-ch_01.html#sigil_toc_id_26">OBSERVING “%C/A” AS A MEASURE OF REWORK</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_01.html#sigil_toc_id_27">THE THREE WAYS: THE PRINCIPLES UNDERPINNING DEVOPS</a>
            </li>
            <li>
              <a href="DOHB-ch_01.html#sigil_toc_id_28">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_02.html">2 The First Way: The Principles of Flow</a>
          <ul>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_29">MAKE OUR WORK VISIBLE</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#Page-__-52">LIMIT WORK IN PROCESS (WIP)</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_30">REDUCE BATCH SIZES</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_31">REDUCE THE NUMBER OF HANDOFFS</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_32">CONTINUALLY IDENTIFY AND ELEVATE OUR CONSTRAINTS</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_33">ELIMINATE HARDSHIPS AND WASTE IN THE VALUE STREAM</a>
            </li>
            <li>
              <a href="DOHB-ch_02.html#sigil_toc_id_34">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_03.html">3 The Second Way: The Principles of Feedback</a>
          <ul>
            <li>
              <a href="DOHB-ch_03.html#sigil_toc_id_35">WORKING SAFELY WITHIN COMPLEX SYSTEMS</a>
            </li>
            <li>
              <a href="DOHB-ch_03.html#Page-__-64">SEE PROBLEMS AS THEY OCCUR</a>
            </li>
            <li>
              <a href="DOHB-ch_03.html#sigil_toc_id_36">SWARM AND SOLVE PROBLEMS TO BUILD NEW KNOWLEDGE</a>
            </li>
            <li>
              <a href="DOHB-ch_03.html#sigil_toc_id_37">KEEP PUSHING QUALITY CLOSER TO THE SOURCE</a>
            </li>
            <li>
              <a href="DOHB-ch_03.html#Page-__-69">ENABLE OPTIMIZING FOR DOWNSTREAM WORK CENTERS</a>
            </li>
            <li>
              <a href="DOHB-ch_03.html#sigil_toc_id_38">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_04.html">4 The Third Way: The Principles of Continual Learning and Experimentation</a>
          <ul>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_39">ENABLING ORGANIZATIONAL LEARNING AND A SAFETY CULTURE</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_40">INSTITUTIONALIZE THE IMPROVEMENT OF DAILY WORK</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_41">TRANSFORM LOCAL DISCOVERIES INTO GLOBAL IMPROVEMENTS</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#Page-__-78">INJECT RESILIENCE PATTERNS INTO OUR DAILY WORK</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_42">LEADERS REINFORCE A LEARNING CULTURE</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_43">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_04.html#sigil_toc_id_44">PART I CONCLUSION</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-pt_02_text.html">Part II Where to Start</a>
      <ul>
        <li>
          <a href="DOHB-pt_02_text.html#sigil_toc_id_45">Introduction</a>
        </li>
        <li>
          <a href="DOHB-ch_05.html">5 Selecting Which Value Stream to Start With</a>
          <ul>
            <li>
              <a href="DOHB-ch_05.html#sigil_toc_id_46">GREENFIELD VS. BROWNFIELD SERVICES</a>
            </li>
            <li>
              <a href="DOHB-ch_05.html#sigil_toc_id_47">CONSIDER BOTH SYSTEMS OF RECORD AND SYSTEMS OF ENGAGEMENT</a>
            </li>
            <li>
              <a href="DOHB-ch_05.html#sigil_toc_id_48">START WITH THE MOST SYMPATHETIC AND INNOVATIVE GROUPS</a>
            </li>
            <li>
              <a href="DOHB-ch_05.html#sigil_toc_id_49">EXPANDING DEVOPS ACROSS OUR ORGANIZATION</a>
            </li>
            <li>
              <a href="DOHB-ch_05.html#Page-__-96">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_06.html">6 Understanding the Work in Our Value Stream, Making it Visible, and Expanding it Across the Organization</a>
          <ul>
            <li>
              <a href="DOHB-ch_06.html#Page-__-100">IDENTIFYING THE TEAMS SUPPORTING OUR VALUE STREAM</a>
            </li>
            <li>
              <a href="DOHB-ch_06.html#Page-__-101">CREATE A VALUE STREAM MAP TO SEE THE WORK</a>
            </li>
            <li>
              <a href="DOHB-ch_06.html#sigil_toc_id_50">CREATING A DEDICATED TRANSFORMATION TEAM</a>
              <ul>
                <li>
                  <a href="DOHB-ch_06.html#sigil_toc_id_51">AGREE ON A SHARED GOAL</a>
                </li>
                <li>
                  <a href="DOHB-ch_06.html#sigil_toc_id_52">KEEP OUR IMPROVEMENT PLANNING HORIZONS SHORT</a>
                </li>
                <li>
                  <a href="DOHB-ch_06.html#sigil_toc_id_53">RESERVE 20% OF CYCLES FOR NON-FUNCTIONAL REQUIREMENTS AND REDUCING TECHNICAL DEBT</a>
                </li>
                <li>
                  <a href="DOHB-ch_06.html#sigil_toc_id_54">INCREASE THE VISIBILITY OF WORK</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_06.html#sigil_toc_id_55">USE TOOLS TO REINFORCE DESIRED BEHAVIOR</a>
            </li>
            <li>
              <a href="DOHB-ch_06.html#sigil_toc_id_56">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_07.html">7 How to Design Our Organization and Architecture with Conway’s Law in Mind</a>
          <ul>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_57">ORGANIZATIONAL ARCHETYPES</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#Page-__-118">PROBLEMS OFTEN CAUSED BY OVERLY FUNCTIONAL ORIENTATION (“OPTIMIZING FOR COST”)</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#Page-__-119">ENABLE MARKET-ORIENTED TEAMS (“OPTIMIZING FOR SPEED”)</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_58">MAKING FUNCTIONAL ORIENTATION WORK</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_59">TESTING, OPERATIONS, AND SECURITY AS EVERYONE’S JOB, EVERY DAY</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_60">ENABLE EVERY TEAM MEMBER TO BE A GENERALIST</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_61">FUND NOT PROJECTS, BUT SERVICES AND PRODUCTS</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#Page-__-125">DESIGN TEAM BOUNDARIES IN ACCORDANCE WITH CONWAY’S LAW</a>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_62">CREATE LOOSELY-COUPLED ARCHITECTURES TO ENABLE DEVELOPER PRODUCTIVITY AND SAFETY</a>
              <ul>
                <li>
                  <a href="DOHB-ch_07.html#sigil_toc_id_63">KEEP TEAM SIZES SMALL (THE “TWO-PIZZA TEAM” RULE)</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_07.html#sigil_toc_id_64">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_08.html">8 How to Get Great Outcomes by Integrating Operations into the Daily Work of Development</a>
          <ul>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_65">CREATE SHARED SERVICES TO INCREASE DEVELOPER PRODUCTIVITY</a>
            </li>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_66">EMBED OPS ENGINEERS INTO OUR SERVICE TEAMS</a>
            </li>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_67">ASSIGN AN OPS LIAISON TO EACH SERVICE TEAM</a>
            </li>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_68">INTEGRATE OPS INTO DEV RITUALS</a>
              <ul>
                <li>
                  <a href="DOHB-ch_08.html#sigil_toc_id_69">INVITE OPS TO OUR DEV STANDUPS</a>
                </li>
                <li>
                  <a href="DOHB-ch_08.html#sigil_toc_id_70">INVITE OPS TO OUR DEV RETROSPECTIVES</a>
                </li>
                <li>
                  <a href="DOHB-ch_08.html#sigil_toc_id_71">MAKE RELEVANT OPS WORK VISIBLE ON SHARED KANBAN BOARDS</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_72">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_08.html#sigil_toc_id_73">PART II CONCLUSION</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-pt_03.html">PART III—THE FIRST WAY: THE TECHNICAL PRACTICES OF FLOW</a>
      <ul>
        <li>
          <a href="DOHB-ch_09.html">9 Create the Foundations of Our Deployment Pipeline</a>
          <ul>
            <li>
              <a href="DOHB-ch_09.html#Page-__-149">ENABLE ON DEMAND CREATION OF DEV, TEST, AND PRODUCTION ENVIRONMENTS</a>
            </li>
            <li>
              <a href="DOHB-ch_09.html#sigil_toc_id_74">CREATE OUR SINGLE REPOSITORY OF TRUTH FOR THE ENTIRE SYSTEM</a>
            </li>
            <li>
              <a href="DOHB-ch_09.html#Page-__-153">MAKE INFRASTRUCTURE EASIER TO REBUILD THAN TO REPAIR</a>
            </li>
            <li>
              <a href="DOHB-ch_09.html#sigil_toc_id_75">MODIFY OUR DEFINITION OF DEVELOPMENT “DONE” TO INCLUDE RUNNING IN PRODUCTION-LIKE ENVIRONMENTS</a>
            </li>
            <li>
              <a href="DOHB-ch_09.html#sigil_toc_id_76">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_10.html">10 Enable Fast and Reliable Automated Testing</a>
          <ul>
            <li>
              <a href="DOHB-ch_10.html#Page-__-161">CONTINUOUSLY BUILD, TEST, AND INTEGRATE OUR CODE AND ENVIRONMENTS</a>
            </li>
            <li>
              <a href="DOHB-ch_10.html#sigil_toc_id_77">BUILD A FAST AND RELIABLE AUTOMATED VALIDATION TEST SUITE</a>
              <ul>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_78">CATCH ERRORS AS EARLY IN OUR AUTOMATED TESTING AS POSSIBLE</a>
                </li>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_79">ENSURE TESTS RUN QUICKLY (IN PARALLEL, IF NECESSARY)</a>
                </li>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_80">WRITE OUR AUTOMATED TESTS BEFORE WE WRITE THE CODE (“TEST-DRIVEN DEVELOPMENT”)</a>
                </li>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_81">AUTOMATE AS MANY OF OUR MANUAL TESTS AS POSSIBLE</a>
                </li>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_82">INTEGRATE PERFORMANCE TESTING INTO OUR TEST SUITE</a>
                </li>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_83">INTEGRATE NON-FUNCTIONAL REQUIREMENTS TESTING INTO OUR TEST SUITE</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_10.html#sigil_toc_id_84">PULL OUR ANDON CORD WHEN THE DEPLOYMENT PIPELINE BREAKS</a>
              <ul>
                <li>
                  <a href="DOHB-ch_10.html#sigil_toc_id_85">WHY WE NEED TO PULL THE ANDON CORD</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_10.html#sigil_toc_id_86">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_11.html">11 Enable and Practice Continuous Integration</a>
          <ul>
            <li>
              <a href="DOHB-ch_11.html#sigil_toc_id_87">SMALL BATCH DEVELOPMENT AND WHAT HAPPENS WHEN WE COMMIT CODE TO TRUNK INFREQUENTLY</a>
            </li>
            <li>
              <a href="DOHB-ch_11.html#Page-__-182">ADOPT TRUNK-BASED DEVELOPMENT PRACTICES</a>
            </li>
            <li>
              <a href="DOHB-ch_11.html#Page-__-185">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_12.html">12 Automate and Enable Low-Risk Releases</a>
          <ul>
            <li>
              <a href="DOHB-ch_12.html#sigil_toc_id_88">AUTOMATE OUR DEPLOYMENT PROCESS</a>
              <ul>
                <li>
                  <a href="DOHB-ch_12.html#sigil_toc_id_89">ENABLE AUTOMATED SELF-SERVICE DEPLOYMENTS</a>
                </li>
                <li>
                  <a href="DOHB-ch_12.html#sigil_toc_id_90">INTEGRATE CODE DEPLOYMENT INTO THE DEPLOYMENT PIPELINE</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_12.html#Page-__-199">DECOUPLE DEPLOYMENTS FROM RELEASES</a>
              <ul>
                <li>
                  <a href="DOHB-ch_12.html#sigil_toc_id_91">ENVIRONMENT-BASED RELEASE PATTERNS</a>
                  <ul>
                    <li>
                      <a href="DOHB-ch_12.html#sigil_toc_id_92">The Blue-Green Deployment Pattern</a>
                    </li>
                    <li>
                      <a href="DOHB-ch_12.html#sigil_toc_id_93">Dealing with Database Changes</a>
                    </li>
                    <li>
                      <a href="DOHB-ch_12.html#sigil_toc_id_94">The Canary and Cluster Immune System Release Patterns</a>
                    </li>
                  </ul>
                </li>
                <li>
                  <a href="DOHB-ch_12.html#sigil_toc_id_95">APPLICATION-BASED PATTERNS TO ENABLE SAFER RELEASES</a>
                  <ul>
                    <li>
                      <a href="DOHB-ch_12.html#sigil_toc_id_96">Implement Feature Toggles</a>
                    </li>
                    <li>
                      <a href="DOHB-ch_12.html#sigil_toc_id_97">Perform Dark Launches</a>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_12.html#Page-__-209">SURVEY OF CONTINUOUS DELIVERY AND CONTINUOUS DEPLOYMENT IN PRACTICE</a>
            </li>
            <li>
              <a href="DOHB-ch_12.html#sigil_toc_id_98">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_13.html">13 Architect for Low-Risk Releases</a>
          <ul>
            <li>
              <a href="DOHB-ch_13.html#Page-__-214">AN ARCHITECTURE THAT ENABLES PRODUCTIVITY, TESTABILITY, AND SAFETY</a>
            </li>
            <li>
              <a href="DOHB-ch_13.html#sigil_toc_id_99">ARCHITECTURAL ARCHETYPES: MONOLITHS VS. MICROSERVICES</a>
            </li>
            <li>
              <a href="DOHB-ch_13.html#sigil_toc_id_100">USE THE STRANGLER APPLICATION PATTERN TO SAFELY EVOLVE OUR ENTERPRISE ARCHITECTURE</a>
            </li>
            <li>
              <a href="DOHB-ch_13.html#Page-__-222">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_13.html#sigil_toc_id_101">PART III CONCLUSION</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-pt_04_text.html">PART IV—THE SECOND WAY: THE TECHNICAL PRACTICES OF FEEDBACK</a>
      <ul>
        <li>
          <a href="DOHB-pt_04_text.html#sigil_toc_id_102">Introduction</a>
        </li>
        <li>
          <a href="DOHB-ch_14.html">14 Create Telemetry to Enable Seeing and Solving Problems</a>
          <ul>
            <li>
              <a href="DOHB-ch_14.html#Page-__-233">CREATE OUR CENTRALIZED TELEMETRY INFRASTRUCTURE</a>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_103">CREATE APPLICATION LOGGING TELEMETRY THAT HELPS PRODUCTION</a>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_104">USE TELEMETRY TO GUIDE PROBLEM SOLVING</a>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_105">ENABLE CREATION OF PRODUCTION METRICS AS PART OF DAILY WORK</a>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_106">CREATE SELF-SERVICE ACCESS TO TELEMETRY AND INFORMATION RADIATORS</a>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_107">FIND AND FILL ANY TELEMETRY GAPS</a>
              <ul>
                <li>
                  <a href="DOHB-ch_14.html#sigil_toc_id_108">APPLICATION AND BUSINESS METRICS</a>
                </li>
                <li>
                  <a href="DOHB-ch_14.html#Page-__-247">INFRASTRUCTURE METRICS</a>
                </li>
                <li>
                  <a href="DOHB-ch_14.html#sigil_toc_id_109">OVERLAYING OTHER RELEVANT INFORMATION ONTO OUR METRICS</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_14.html#sigil_toc_id_110">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_15.html">15 Analyze Telemetry to Better Anticipate Problems and Achieve Goals</a>
          <ul>
            <li>
              <a href="DOHB-ch_15.html#sigil_toc_id_111">USE MEANS AND STANDARD DEVIATIONS TO DETECT POTENTIAL PROBLEMS</a>
            </li>
            <li>
              <a href="DOHB-ch_15.html#sigil_toc_id_112">INSTRUMENT AND ALERT ON UNDESIRED OUTCOMES</a>
            </li>
            <li>
              <a href="DOHB-ch_15.html#sigil_toc_id_113">PROBLEMS THAT ARISE WHEN OUR TELEMETRY DATA HAS NON-GAUSSIAN DISTRIBUTION</a>
            </li>
            <li>
              <a href="DOHB-ch_15.html#sigil_toc_id_114">USING ANOMALY DETECTION TECHNIQUES</a>
            </li>
            <li>
              <a href="DOHB-ch_15.html#sigil_toc_id_115">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_16.html">16 Enable Feedback So Development and Operations Can Safely Deploy Code</a>
          <ul>
            <li>
              <a href="DOHB-ch_16.html#sigil_toc_id_116">USE TELEMETRY TO MAKE DEPLOYMENTS SAFER</a>
            </li>
            <li>
              <a href="DOHB-ch_16.html#sigil_toc_id_117">DEV SHARES PAGER ROTATION DUTIES WITH OPS</a>
            </li>
            <li>
              <a href="DOHB-ch_16.html#Page-__-271">HAVE DEVELOPERS FOLLOW WORK DOWNSTREAM</a>
            </li>
            <li>
              <a href="DOHB-ch_16.html#sigil_toc_id_118">HAVE DEVELOPERS INITIALLY SELF-MANAGE THEIR PRODUCTION SERVICE</a>
            </li>
            <li>
              <a href="DOHB-ch_16.html#sigil_toc_id_119">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_17.html">17 Integrate Hypothesis-Driven Development and A/B Testing into Our Daily Work</a>
          <ul>
            <li>
              <a href="DOHB-ch_17.html#Page-__-283">A BRIEF HISTORY OF A/B TESTING</a>
            </li>
            <li>
              <a href="DOHB-ch_17.html#Page-__-284">INTEGRATING A/B TESTING INTO OUR FEATURE TESTING</a>
            </li>
            <li>
              <a href="DOHB-ch_17.html#sigil_toc_id_120">INTEGRATE A/B TESTING INTO OUR RELEASE</a>
            </li>
            <li>
              <a href="DOHB-ch_17.html#Page-__-286">INTEGRATING A/B TESTING INTO OUR FEATURE PLANNING</a>
            </li>
            <li>
              <a href="DOHB-ch_17.html#Page-__-288">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_18.html">18 Create Review and Coordination Processes to Increase Quality of Our Current Work</a>
          <ul>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_121">THE DANGERS OF CHANGE APPROVAL PROCESSES</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_122">POTENTIAL DANGERS OF “OVERLY CONTROLLING CHANGES”</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#Page-__-296">ENABLE COORDINATION AND SCHEDULING OF CHANGES</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_123">ENABLE PEER REVIEW OF CHANGES</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#Page-__-300">POTENTIAL DANGERS OF DOING MORE MANUAL TESTING AND CHANGE FREEZES</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#section-below">ENABLE PAIR PROGRAMMING TO IMPROVE ALL OUR CHANGES</a>
              <ul>
                <li>
                  <a href="DOHB-ch_18.html#Page-__-303">EVALUATING THE EFFECTIVENESS OF PULL REQUEST PROCESSES</a>
                </li>
              </ul>
            </li>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_124">FEARLESSLY CUT BUREAUCRATIC PROCESSES</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_125">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_18.html#sigil_toc_id_126">PART IV CONCLUSION</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-pt_05_text.html">PART V—THE THIRD WAY: THE TECHNICAL PRACTICES OF CONTINUAL LEARNING AND EXPERIMENTATION</a>
      <ul>
        <li>
          <a href="DOHB-pt_05_text.html#sigil_toc_id_127">Introduction</a>
        </li>
        <li>
          <a href="DOHB-ch_19.html">19 Enable and Inject Learning into Daily Work</a>
          <ul>
            <li>
              <a href="DOHB-ch_19.html#Page-__-315">ESTABLISH A JUST, LEARNING CULTURE</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#sigil_toc_id_128">SCHEDULE BLAMELESS POST-MORTEM MEETINGS AFTER ACCIDENTS OCCUR</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#sigil_toc_id_129">PUBLISH OUR POST-MORTEMS AS WIDELY AS POSSIBLE</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#sigil_toc_id_130">DECREASE INCIDENT TOLERANCES TO FIND EVER-WEAKER FAILURE SIGNALS</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#Page-__-322">REDEFINE FAILURE AND ENCOURAGE CALCULATED RISK-TAKING</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#sigil_toc_id_131">INJECT PRODUCTION FAILURES TO ENABLE RESILIENCE AND LEARNING</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#Page-__-324">INSTITUTE GAME DAYS TO REHEARSE FAILURES</a>
            </li>
            <li>
              <a href="DOHB-ch_19.html#sigil_toc_id_132">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_20.html">20 Convert Local Discoveries into Global Improvements</a>
          <ul>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_133">USE CHAT ROOMS AND CHAT BOTS TO AUTOMATE AND CAPTURE ORGANIZATIONAL KNOWLEDGE</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_134">AUTOMATE STANDARDIZED PROCESSES IN SOFTWARE FOR RE-USE</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_135">CREATE A SINGLE, SHARED SOURCE CODE REPOSITORY FOR OUR ENTIRE ORGANIZATION</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_136">SPREAD KNOWLEDGE BY USING AUTOMATED TESTS AS DOCUMENTATION AND COMMUNITIES OF PRACTICE</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_137">DESIGN FOR OPERATIONS THROUGH CODIFIED NON-FUNCTIONAL REQUIREMENTS</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_138">BUILD REUSABLE OPERATIONS USER STORIES INTO DEVELOPMENT</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#Page-__-336">ENSURE TECHNOLOGY CHOICES HELP ACHIEVE ORGANIZATIONAL GOALS</a>
            </li>
            <li>
              <a href="DOHB-ch_20.html#sigil_toc_id_139">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_21.html">21 Reserve Time to Create Organizational Learning and Improvement</a>
          <ul>
            <li>
              <a href="DOHB-ch_21.html#Page-__-342">INSTITUTIONALIZE RITUALS TO PAY DOWN TECHNICAL DEBT</a>
            </li>
            <li>
              <a href="DOHB-ch_21.html#sigil_toc_id_140">ENABLE EVERYONE TO TEACH AND LEARN</a>
            </li>
            <li>
              <a href="DOHB-ch_21.html#sigil_toc_id_141">SHARE YOUR EXPERIENCES FROM DEVOPS CONFERENCES</a>
            </li>
            <li>
              <a href="DOHB-ch_21.html#Page-__-347">CREATE INTERNAL CONSULTING AND COACHES TO SPREAD PRACTICES</a>
            </li>
            <li>
              <a href="DOHB-ch_21.html#sigil_toc_id_142">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_21.html#sigil_toc_id_143">CONCLUSION TO PART V</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_22.html">22 Information Security as Everyone’s Job, Every Day</a>
          <ul>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_144">INTEGRATE SECURITY INTO DEVELOPMENT ITERATION DEMONSTRATIONS</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#Page-__-357">INTEGRATE SECURITY INTO DEFECT TRACKING AND POST-MORTEMS</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_145">INTEGRATE PREVENTIVE SECURITY CONTROLS INTO SHARED SOURCE CODE REPOSITORIES AND SHARED SERVICES</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#Page-__-359">INTEGRATE SECURITY INTO OUR DEPLOYMENT PIPELINE</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_146">ENSURE SECURITY OF THE APPLICATION</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_147">ENSURE SECURITY OF OUR SOFTWARE SUPPLY CHAIN</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#Page-__-366">ENSURE SECURITY OF THE ENVIRONMENT</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_148">INTEGRATE INFORMATION SECURITY INTO PRODUCTION TELEMETRY</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_149">CREATING SECURITY TELEMETRY IN OUR APPLICATIONS</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_150">CREATING SECURITY TELEMETRY IN OUR ENVIRONMENT</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_151">PROTECT OUR DEPLOYMENT PIPELINE</a>
            </li>
            <li>
              <a href="DOHB-ch_22.html#sigil_toc_id_152">CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_23.html">23 Protecting the Deployment Pipeline</a>
          <ul>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_153">INTEGRATE SECURITY AND COMPLIANCE INTO CHANGE APPROVAL PROCESSES</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_154">RE-CATEGORIZE THE MAJORITY OF OUR LOWER RISK CHANGES AS STANDARD CHANGES</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_155">WHAT TO DO WHEN CHANGES ARE CATEGORIZED AS NORMAL CHANGES</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_156">REDUCE RELIANCE ON SEPARATION OF DUTY</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_157">ENSURE DOCUMENTATION AND PROOF FOR AUDITORS AND COMPLIANCE OFFICERS</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#Page-__-384">CONCLUSION</a>
            </li>
            <li>
              <a href="DOHB-ch_23.html#sigil_toc_id_158">PART VI CONCLUSION</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-ch_23-CTA.html">A Call to Action</a>
          <ul>
            <li>
              <a href="DOHB-ch_23-CTA.html#sigil_toc_id_159">Conclusion to the DevOps Handbook</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-END-BM.html">Appendices</a>
      <ul>
        <li>
          <a href="DOHB-END-BM.html#appendix-1">APPENDIX 1 THE CONVERGENCE OF DEVOPS</a>
          <ul>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_160">THE LEAN MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_161">THE AGILE MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_162">THE VELOCITY CONFERENCE MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_163">THE AGILE INFRASTRUCTURE MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_164">THE CONTINUOUS DELIVERY MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_165">THE TOYOTA KATA MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_166">THE LEAN STARTUP MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_167">THE LEAN UX MOVEMENT</a>
            </li>
            <li>
              <a href="DOHB-END-BM.html#sigil_toc_id_168">THE RUGGED COMPUTING MOVEMENT</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-2">APPENDIX 2 THEORY OF CONSTRAINTS AND CORE, CHRONIC CONFLICTS</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-3">APPENDIX 3 TABULAR FORM OF DOWNWARD SPIRAL</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-4">APPENDIX 4 THE DANGERS OF HANDOFFS AND QUEUES</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-5">APPENDIX 5 MYTHS OF INDUSTRIAL SAFETY</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-6">APPENDIX 6 THE TOYOTA ANDON CORD</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-7">APPENDIX 7 COTS SOFTWARE</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-8">APPENDIX 8 POST-MORTEM MEETINGS</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-9">APPENDIX 9 THE SIMIAN ARMY</a>
        </li>
        <li>
          <a href="DOHB-END-BM.html#appendix-10">APPENDIX 10 TRANSPARENT UPTIME</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-END-BM-additional.html">Additional Resources</a>
    </li>
    <li>
      <a href="DOHB-END-BM-additional.html#_idParaDest-46">Endnotes</a>
      <ul>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_169">INTRODUCTION</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#Page-__-409">PART I INTRODUCTION</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_170">CHAPTER 1</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_171">CHAPTER 2</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_172">CHAPTER 3</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_173">CHAPTER 4</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_174">CHAPTER 5</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_175">CHAPTER 6</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_176">CHAPTER 7</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_177">CHAPTER 8</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_178">CHAPTER 9</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_179">CHAPTER 10</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_180">CHAPTER 11</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_181">CHAPTER 12</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_182">CHAPTER 13</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_183">CHAPTER 14</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#Page-__-430">CHAPTER 15</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_184">CHAPTER 16</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_185">CHAPTER 17</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_186">CHAPTER 18</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_187">CHAPTER 19</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_188">CHAPTER 20</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_189">CHAPTER 21</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_190">CHAPTER 22</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#Page-__-445">CHAPTER 23</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_191">CONCLUSION</a>
        </li>
        <li>
          <a href="DOHB-END-BM-additional.html#sigil_toc_id_192">APPENDIX</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-END-BM-index.html">Index</a>
      <ul>
        <li>
          <a href="DOHB-END-BM-index.html#index_list">Symbols Numbers A B C D E F G H I J K L M N O P Q R S T U V W Y Z</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-END-BM-ack.html">Acknowledgments</a>
      <ul>
        <li>
          <a href="DOHB-END-BM-ack.html#sigil_toc_id_193">Jez Humble</a>
        </li>
        <li>
          <a href="DOHB-END-BM-ack.html#sigil_toc_id_194">John Willis</a>
        </li>
        <li>
          <a href="DOHB-END-BM-ack.html#sigil_toc_id_195">Patrick Debois</a>
        </li>
        <li>
          <a href="DOHB-END-BM-ack.html#Page-__-494">Gene Kim</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="DOHB-END-BM-aut.html">Author Biographies</a>
      <ul>
        <li>
          <a href="DOHB-END-BM-aut.html#sigil_toc_id_196">GENE KIM</a>
        </li>
        <li>
          <a href="DOHB-END-BM-aut.html#sigil_toc_id_197">JEZ HUMBLE</a>
        </li>
        <li>
          <a href="DOHB-END-BM-aut.html#sigil_toc_id_198">PATRICK DEBOIS</a>
        </li>
        <li>
          <a href="DOHB-END-BM-aut.html#sigil_toc_id_199">JOHN WILLIS</a>
        </li>
      </ul>
    </li>
  </ul>
</div>


  </div>
  

  <div class="calibreEbNav">
    
      <a href="DOHB-ch_09.html" class="calibreAPrev">previous page</a>
    

    <a href="../../../p4zbp-8mxvm.html" class="calibreAHome"> start</a>

    
      <a href="DOHB-ch_11.html" class="calibreANext"> next page</a>
    
  </div>

</div>

</body>
</html>
